{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Model and deploy as Webservice\n",
    "\n",
    "This example shows how to deploy a Webservice in step-by-step fashion:\n",
    "\n",
    " 1. Register Model\n",
    " 2. Deploy Model as Webservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1) If you are using an Azure Machine Learning Notebook VM, you are all set. \n",
    "\n",
    "2) Run through [1_Bert_StackOverflow_Training](1_Bert_StackOverflow_Training.ipynb) Notebook first to register your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.62\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "\n",
    "Initialize a workspace object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: abe-gpu-ws\n",
      "Azure region: westus2\n",
      "Subscription id: 15ae9cb6-95c1-483d-a0e3-b1a1a3b06324\n",
      "Resource group: osomorog\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Model\n",
    "\n",
    "You can retrieve your BERT Model created in the first notebook. [1_Bert_StackOverflow_Training](1_Bert_StackOverflow_Training.ipynb) Notebook first to register your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='abe-gpu-ws', subscription_id='15ae9cb6-95c1-483d-a0e3-b1a1a3b06324', resource_group='osomorog'), name=bert-stackoverflow, id=bert-stackoverflow:1, version=1, tags={}, properties={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "model = ws.models['bert-stackoverflow']\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download bert-stackoverflow source code into local repository and install submodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading repo...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Downloading repo...')\n",
    "project_folder = './bert-stackoverflow'\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "os.system('git clone https://github.com/AbeOmor/bert-stackoverflow/tree/patch-1 && cd bert-stackoverflow && git submodule update --init --recursive && cd ..')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy as web service\n",
    "\n",
    "Once you've tested the model and are satisfied with the results, deploy the model as a web service hosted in ACI. \n",
    "\n",
    "To build the correct environment for ACI, provide the following:\n",
    "* A scoring script to show how to use the model\n",
    "* An environment file to show what packages need to be installed\n",
    "* A configuration file to build the ACI\n",
    "* The model you trained before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now create and/or use an Environment object when deploying a Webservice. The Environment can have been previously registered with your Workspace, or it will be registered with it as a part of the Webservice deployment. Only Environments that were created using azureml-defaults version 1.0.48 or later will work with this new handling however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(conda_packages=['numpy','pandas'],\n",
    "                                 pip_packages=['numpy','pandas','inference-schema[numpy-support]','azureml-defaults','tensorflow==1.13.2'])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the content of the `myenv.yml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - numpy\n",
      "  - pandas\n",
      "  - inference-schema[numpy-support]\n",
      "  - azureml-defaults==1.0.62.*\n",
      "  - tensorflow==1.13.2\n",
      "- numpy\n",
      "- pandas\n",
      "channels:\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"myenv.yml\",\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create configuration file\n",
    "\n",
    "Create a deployment configuration file and specify the number of CPUs and gigabyte of RAM needed for your ACI container. While it depends on your model, the default of 1 core and 1 gigabyte of RAM is usually sufficient for many models. If you feel you need more later, you would have to recreate the image and redeploy the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"model\": \"BERT\",  \"method\" : \"tensorflow\"}, \n",
    "                                               description='Predict StackoverFlow tags with BERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Inference Configuration\n",
    "\n",
    "There is now support for a source directory, you can upload an entire folder from your local machine as dependencies for the Webservice.\n",
    "Note: in that case, your entry_script, conda_file, and extra_docker_file_steps paths are relative paths to the source_directory path.\n",
    "\n",
    "Sample code for using a source directory:\n",
    "\n",
    "```python\n",
    "inference_config = InferenceConfig(source_directory=\"C:/abc\",\n",
    "                                   runtime= \"python\", \n",
    "                                   entry_script=\"x/y/score.py\",\n",
    "                                   conda_file=\"env/myenv.yml\", \n",
    "                                   extra_docker_file_steps=\"helloworld.txt\")\n",
    "```\n",
    "\n",
    " - source_directory = holds source path as string, this entire folder gets added in image so its really easy to access any files within this folder or subfolder\n",
    " - runtime = Which runtime to use for the image. Current supported runtimes are 'spark-py' and 'python\n",
    " - entry_script = contains logic specific to initializing your model and running predictions\n",
    " - conda_file = manages conda and python package dependencies.\n",
    " - extra_docker_file_steps = optional: any extra steps you want to inject into docker file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(source_directory=\"bert-stackoverflow\",\n",
    "                                   runtime= \"python\", \n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"../myenv.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy in ACI\n",
    "Estimated time to complete: **about 5-10 minutes**\n",
    "\n",
    "Configure the image and deploy. The following code goes through these steps:\n",
    "\n",
    "* Build an image using:\n",
    "   * The scoring file (`score.py`)\n",
    "   * The environment file (`myenv.yml`)\n",
    "   * The model file\n",
    "* Register that image under the workspace. \n",
    "* Send the image to the ACI container.\n",
    "* Start up a container in ACI using the image.\n",
    "* Get the web service HTTP endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..........................\n",
      "SucceededACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "CPU times: user 569 ms, sys: 98.2 ms, total: 667 ms\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "aci_service_name = 'bert-stackoverflow-aciservice'\n",
    "\n",
    "try:\n",
    "    # if you want to get existing service below is the command\n",
    "    # since aci name needs to be unique in subscription deleting existing aci if any\n",
    "    # we use aci_service_name to create azure aci\n",
    "    service = Webservice(ws, name=aci_service_name)\n",
    "    if service:\n",
    "        service.delete()\n",
    "except WebserviceException as e:\n",
    "    print()\n",
    "\n",
    "service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test web service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": \"123\",\n",
      "    \"text\": \"I need help with importing a module with tensorflow 2.0\",\n",
      "    \"probabilities\": {\n",
      "      \"c#\": \"0.012589216\",\n",
      "      \".net\": \"0.015036851\",\n",
      "      \"java\": \"0.038416177\",\n",
      "      \"asp.net\": \"0.016928166\",\n",
      "      \"c++\": \"0.046544015\",\n",
      "      \"javascript\": \"0.068582\",\n",
      "      \"php\": \"0.01960367\",\n",
      "      \"python\": \"0.29779866\",\n",
      "      \"sql\": \"0.009429228\",\n",
      "      \"sql-server\": \"0.009171811\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "CPU times: user 3.92 ms, sys: 0 ns, total: 3.92 ms\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "test_sample = json.dumps({\n",
    "    'data': [\n",
    "        {\n",
    "        'id': 123,\n",
    "        'text': 'I need help with importing a module with tensorflow 2.0'\n",
    "        }\n",
    "    ]\n",
    "})\n",
    "\n",
    "#test_sample_encoded = bytes(test_sample, encoding='utf8')\n",
    "prediction = service.run(input_data=test_sample)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View ACI Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/bin/bash: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libtinfo.so.5: no '\n",
      " 'version information available (required by /bin/bash)\\n'\n",
      " '/bin/bash: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libtinfo.so.5: no '\n",
      " 'version information available (required by /bin/bash)\\n'\n",
      " '/bin/bash: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libtinfo.so.5: no '\n",
      " 'version information available (required by /bin/bash)\\n'\n",
      " '/bin/bash: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libtinfo.so.5: no '\n",
      " 'version information available (required by /bin/bash)\\n'\n",
      " 'bash: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libtinfo.so.5: no '\n",
      " 'version information available (required by bash)\\n'\n",
      " '/usr/sbin/nginx: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libcrypto.so.1.0.0: '\n",
      " 'no version information available (required by /usr/sbin/nginx)\\n'\n",
      " '/usr/sbin/nginx: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libcrypto.so.1.0.0: '\n",
      " 'no version information available (required by /usr/sbin/nginx)\\n'\n",
      " '/usr/sbin/nginx: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libssl.so.1.0.0: '\n",
      " 'no version information available (required by /usr/sbin/nginx)\\n'\n",
      " '/usr/sbin/nginx: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libssl.so.1.0.0: '\n",
      " 'no version information available (required by /usr/sbin/nginx)\\n'\n",
      " '/usr/sbin/nginx: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libssl.so.1.0.0: '\n",
      " 'no version information available (required by /usr/sbin/nginx)\\n'\n",
      " '2019-10-02T21:42:05,987228322+00:00 - gunicorn/run \\n'\n",
      " '2019-10-02T21:42:05,987624616+00:00 - rsyslog/run \\n'\n",
      " '2019-10-02T21:42:05,990001385+00:00 - nginx/run \\n'\n",
      " '2019-10-02T21:42:05,987202922+00:00 - iot-server/run \\n'\n",
      " 'EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n'\n",
      " '/bin/bash: '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/libtinfo.so.5: no '\n",
      " 'version information available (required by /bin/bash)\\n'\n",
      " '2019-10-02T21:42:06,081125486+00:00 - iot-server/finish 1 0\\n'\n",
      " '2019-10-02T21:42:06,082276371+00:00 - Exit code 1 is normal. Not restarting '\n",
      " 'iot-server.\\n'\n",
      " 'Starting gunicorn 19.9.0\\n'\n",
      " 'Listening at: http://127.0.0.1:31311 (11)\\n'\n",
      " 'Using worker: sync\\n'\n",
      " 'worker timeout is set to 300\\n'\n",
      " 'Booting worker with pid: 42\\n'\n",
      " 'Initializing logger\\n'\n",
      " 'Starting up app insights client\\n'\n",
      " 'Starting up request id generator\\n'\n",
      " 'Starting up app insight hooks\\n'\n",
      " \"Invoking user's init function\\n\"\n",
      " '2019-10-02 21:42:08.771018: I '\n",
      " 'tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports '\n",
      " 'instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\\n'\n",
      " '2019-10-02 21:42:08.776286: I '\n",
      " 'tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: '\n",
      " '2294685000 Hz\\n'\n",
      " '2019-10-02 21:42:08.776616: I '\n",
      " 'tensorflow/compiler/xla/service/service.cc:150] XLA service 0x48174b0 '\n",
      " 'executing computations on platform Host. Devices:\\n'\n",
      " '2019-10-02 21:42:08.776646: I '\n",
      " 'tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): '\n",
      " '<undefined>, <undefined>\\n'\n",
      " 'From bert-stackoverflow/score.py:24: load (from '\n",
      " 'tensorflow.python.saved_model.loader_impl) is deprecated and will be removed '\n",
      " 'in a future version.\\n'\n",
      " 'Instructions for updating:\\n'\n",
      " 'This function will only be available through the v1 compatibility library as '\n",
      " 'tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There '\n",
      " 'will be a new function for importing SavedModels in Tensorflow 2.0.\\n'\n",
      " 'From '\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: '\n",
      " 'checkpoint_exists (from tensorflow.python.training.checkpoint_management) is '\n",
      " 'deprecated and will be removed in a future version.\\n'\n",
      " 'Instructions for updating:\\n'\n",
      " 'Use standard file APIs to check for files with this prefix.\\n'\n",
      " 'Restoring parameters from '\n",
      " 'azureml-models/bert-stackoverflow/1/exports/1569531193/variables/variables\\n'\n",
      " \"Users's init has completed successfully\\n\"\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: '\n",
      " \"FutureWarning: Passing (type, 1) or '1type' as a synonym of type is \"\n",
      " 'deprecated; in a future version of numpy, it will be understood as (type, '\n",
      " \"(1,)) / '(1,)type'.\\n\"\n",
      " '  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\\n'\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: '\n",
      " \"FutureWarning: Passing (type, 1) or '1type' as a synonym of type is \"\n",
      " 'deprecated; in a future version of numpy, it will be understood as (type, '\n",
      " \"(1,)) / '(1,)type'.\\n\"\n",
      " '  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\\n'\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: '\n",
      " \"FutureWarning: Passing (type, 1) or '1type' as a synonym of type is \"\n",
      " 'deprecated; in a future version of numpy, it will be understood as (type, '\n",
      " \"(1,)) / '(1,)type'.\\n\"\n",
      " '  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\\n'\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: '\n",
      " \"FutureWarning: Passing (type, 1) or '1type' as a synonym of type is \"\n",
      " 'deprecated; in a future version of numpy, it will be understood as (type, '\n",
      " \"(1,)) / '(1,)type'.\\n\"\n",
      " '  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\\n'\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: '\n",
      " \"FutureWarning: Passing (type, 1) or '1type' as a synonym of type is \"\n",
      " 'deprecated; in a future version of numpy, it will be understood as (type, '\n",
      " \"(1,)) / '(1,)type'.\\n\"\n",
      " '  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\\n'\n",
      " '/azureml-envs/azureml_617e8a56e351dc1398e8e025d4c910d2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: '\n",
      " \"FutureWarning: Passing (type, 1) or '1type' as a synonym of type is \"\n",
      " 'deprecated; in a future version of numpy, it will be understood as (type, '\n",
      " \"(1,)) / '(1,)type'.\\n\"\n",
      " '  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\\n'\n",
      " 'Scoring timeout setting is not found. Use default timeout: 3600000 ms\\n'\n",
      " 'Validation Request Content-Type\\n'\n",
      " 'Received input: {\"data\": [{\"id\": 123, \"text\": \"I need help with pytorch\"}]}\\n'\n",
      " 'Headers passed in (total 11):\\n'\n",
      " '\\tHost: localhost:5001\\n'\n",
      " '\\tX-Real-Ip: 127.0.0.1\\n'\n",
      " '\\tX-Forwarded-For: 127.0.0.1\\n'\n",
      " '\\tX-Forwarded-Proto: http\\n'\n",
      " '\\tConnection: close\\n'\n",
      " '\\tContent-Length: 59\\n'\n",
      " '\\tUser-Agent: python-requests/2.22.0\\n'\n",
      " '\\tAccept: */*\\n'\n",
      " '\\tAccept-Encoding: gzip, deflate\\n'\n",
      " '\\tContent-Type: application/json\\n'\n",
      " '\\tX-Ms-Request-Id: 812760e8-43cc-4a20-988b-ec8f71f49e93\\n'\n",
      " 'Scoring Timer is set to 3600.0 seconds\\n'\n",
      " 'Writing example 0 of 1\\n'\n",
      " '*** Example ***\\n'\n",
      " 'guid: 123\\n'\n",
      " 'tokens: [CLS] i need help with p ##yt ##or ##ch [SEP]\\n'\n",
      " 'input_ids: 101 1045 2342 2393 2007 1052 22123 2953 2818 102 0 0 0 0 0 0 0 0 '\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 '\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 '\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n'\n",
      " 'input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 '\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 '\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 '\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n'\n",
      " 'segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 '\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 '\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 '\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\\n'\n",
      " 'label: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] (id = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\\n'\n",
      " 'From bert-stackoverflow/score.py:42: tf_record_iterator (from '\n",
      " 'tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a '\n",
      " 'future version.\\n'\n",
      " 'Instructions for updating:\\n'\n",
      " 'Use eager execution and: \\n'\n",
      " '`tf.data.TFRecordDataset(path)`\\n'\n",
      " \"[{'id': '123', 'text': 'I need help with pytorch', 'probabilities': {'c#': \"\n",
      " \"'0.031254917', '.net': '0.030932575', 'java': '0.01577288', 'asp.net': \"\n",
      " \"'0.034988403', 'c++': '0.03480339', 'javascript': '0.07773459', 'php': \"\n",
      " \"'0.13981712', 'python': '0.5095133', 'sql': '0.012264088', 'sql-server': \"\n",
      " \"'0.010879521'}}]\\n\"\n",
      " '200\\n'\n",
      " '127.0.0.1 - - [02/Oct/2019:21:42:20 +0000] \"POST /score HTTP/1.0\" 200 461 '\n",
      " '\"-\" \"python-requests/2.22.0\"\\n')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete ACI to clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
